{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "2c3412a4-039b-4229-9387-9321169f16eb",
        "_uuid": "8def9627e9d48b26de3159fc9a2ec38e854ab16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7vCoysi4BCn0",
        "outputId": "d02218d2-7f62-4417-f6af-90d9f4d90401"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-695361520314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ls', '../input']' returned non-zero exit status 2."
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c56a778-ba24-4d51-a89d-a16b7da3f47c",
        "_uuid": "a04a2a1268aabc722a26e5aada6921afd8b19e2f",
        "id": "qqgnQn06BCn6"
      },
      "source": [
        "# Brief Info\n",
        "\n",
        "In this work, we will train a CNN classifier using Keras with the guidelines described in [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python).\n",
        "\n",
        "Our strategy will be using 20% of the train data (12000 data rows) as a validation set to optimize the classifier, while keeping test data to finally evaluate the accuracy of the model on the data it has never seen.\n",
        "\n",
        "kernel :\n",
        "https://www.kaggle.com/bugraokcu/cnn-with-keras\n",
        "\n",
        "#### Note\n",
        "Since I was not sure if the data was already shuffled, I didn't pass `validation_split=0.2` to _fit()_ and instead explicitly shuffled and split the validation data, as `validation_split` [would](https://keras.io/getting-started/faq/#how-is-the-validation-split-computed) use last 20% of the data in that case."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "T5eXAlngGNfC",
        "outputId": "ed063dd5-28e7-4b90-a9db-686ab451b5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8a7aac514115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
        "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0",
        "id": "pUFbHaFRGN_N"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "data_train = pd.read_csv('../input/fashion-mnist_train.csv')\n",
        "data_test = pd.read_csv('../input/fashion-mnist_test.csv')\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "X = np.array(data_train.iloc[:, 1:])\n",
        "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
        "\n",
        "#Here we split validation data to optimiza classifier during training\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "#Test data\n",
        "X_test = np.array(data_test.iloc[:, 1:])\n",
        "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
        "\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_val /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
        "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0",
        "id": "rMY65F47BCn9"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train = pd.read_csv('../input/fashion-mnist_train.csv')\n",
        "data_test = pd.read_csv('../input/fashion-mnist_test.csv')\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "X = np.array(data_train.iloc[:, 1:])\n",
        "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
        "\n",
        "#Here we split validation data to optimiza classifier during training\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "#Test data\n",
        "X_test = np.array(data_test.iloc[:, 1:])\n",
        "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
        "\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_val /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0599166d-b975-4c88-8b91-071a8f4fb0cd",
        "_uuid": "0e9db73157e2c0e481bf3d73892d8d29263aa56f",
        "collapsed": true,
        "id": "_uRD6Br6BCn_"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "#input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4543df54-7373-49f8-a23a-6d8062eefe38",
        "_uuid": "9de535d8a446b7168ac3790445610425527c8a47",
        "id": "nYaPrgwlBCoA"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c9d072ca-23e7-4608-a9d8-dc818715d6e3",
        "_uuid": "1e85d4b1d5fb567f2aad6bd82da969629e585f14",
        "id": "uA6rdEF7BCoB"
      },
      "source": [
        "### Training\n",
        "Let's `fit()`! Note that `fit()` will return a _History_ object which we can use to plot training vs. validation accuracy and loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f24bf149-70e5-43f2-8574-117606493c85",
        "_uuid": "71b754f661ab2bba5e0d2c280d033a57300ef7e2",
        "scrolled": false,
        "id": "rU-qz3PiBCoC"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, y_val))\n",
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4b6cb78-1ef8-46ba-b72d-49a49c81bff0",
        "_uuid": "48787728c57ad402547540b5d528aabbd8b20c0d",
        "id": "7kn0Eo2xBCoD"
      },
      "outputs": [],
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f860c207-af4d-4c32-b4d2-4ea2d39902fe",
        "_uuid": "d18bc5dd0ec23cda8ea5ad846b9877704f484951",
        "id": "x_4j8dr3BCoE"
      },
      "source": [
        "### Results\n",
        "It turns out our classifier does better then the best baseline reported [here](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/), which is an SVM classifier with mean accuracy of 0.897.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "00dc5434-a008-490d-bb89-a394cf95c4bc",
        "_uuid": "adbb96b3d90dcab280f06341a8483f246f583a03",
        "id": "RfOIWDJSBCoF"
      },
      "source": [
        "\n",
        "Let's plot training and validation accuracy as well as loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "324c3a68-6381-4a39-a5a1-8fac766150c0",
        "_uuid": "042117c73a10d7cbda6bc42ab60f9b0407cdf2c1",
        "id": "JNBEdYUwBCoG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1311601b-9a53-4e59-adcd-4365c811f85e",
        "_uuid": "28e5331842de7baaffb3a1e74f6a4c03e140759a",
        "id": "uvMMV4zGBCoH"
      },
      "source": [
        "### Classification Report\n",
        "We can summarize the performance of our classifier as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "721514ef-520b-42a2-9d57-2f82fbae8393",
        "_uuid": "0275d1189e6425353537fa3ebe5d97d7b6759551",
        "collapsed": true,
        "id": "jzUQ5yw2BCoH"
      },
      "outputs": [],
      "source": [
        "#get the predictions for the test data\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "\n",
        "#get the indices to be plotted\n",
        "y_true = data_test.iloc[:, 0]\n",
        "correct = np.nonzero(predicted_classes==y_true)[0]\n",
        "incorrect = np.nonzero(predicted_classes!=y_true)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2dfc23f6-e0be-4014-8ce1-c6a33b1eccde",
        "_uuid": "cc30fc7238f09f2372f718f17bd0f724fe898736",
        "id": "b21r-YGeBCoI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
        "print(classification_report(y_true, predicted_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dc36576e-c630-4581-89fe-3bed02c378bb",
        "_uuid": "2863d680886cc22a2e6f11270b411e435410adaf",
        "id": "arE0toPBBCoJ"
      },
      "source": [
        "It's apparent that our classifier is underperforming for class 6 in terms of both precision and recall. For class 2, classifier is slightly lacking precision whereas it is slightly lacking recall (i.e. missed) for class 4.\n",
        "\n",
        "Perhaps we would gain more insight after visualizing the correct and incorrect predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "866ef2af-d4e1-4697-bf87-9dcaa7cba363",
        "_uuid": "6a78901cefbe9a3bdf89cc1d22ee910970cfaf93",
        "id": "T-rbmLFXBCoJ"
      },
      "source": [
        "Here is a subset of correctly predicted classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a33d457-ff62-4e32-81d7-89a6cdc1106d",
        "_uuid": "d8148b3557ac27d216e0137bbeae06379c829779",
        "id": "wjjj3UpKBCoK"
      },
      "outputs": [],
      "source": [
        "for i, correct in enumerate(correct[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_true[correct]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9726e897-4d69-44d5-a1d5-358d316b5141",
        "_uuid": "a22f4456fa1c09e609db1a6c0e8eb1438087fa91",
        "id": "l6cG5nI5BCoK"
      },
      "source": [
        "And here is a subset of incorrectly predicted classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "803d7c3f-2099-420d-9612-dcf617d6cbe0",
        "_uuid": "fa4d360a4e77bd3d83490065351860b1d9f58f8b",
        "id": "BV3PmnsuBCoK"
      },
      "outputs": [],
      "source": [
        "for i, incorrect in enumerate(incorrect[0:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_true[incorrect]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cd66b1b1-db6f-47e4-aa2e-3ce516979fa3",
        "_uuid": "89881c6e4d1169ac543b5de992832d9e423dfdde",
        "id": "CqTz961WBCoL"
      },
      "source": [
        "It looks like diversity of the similar patterns present on multiple classes effect the performance of the classifier although CNN is a robust architechture. A jacket, a shirt, and a long-sleeve blouse has similar patterns: long sleeves (or not!), buttons (or not!), and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U9yek-IIBCoL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "03_cnn_with_keras.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}